Name: Malange Maduvha
Student Number : 23923173 
Cos 781: Project

 Machine Translation for Low-Resource Languages
 
 Overview 

Machine translation has made rapid advances in recent years. Millions of people are using it today in online translation systems and mobile applications to communicate across language barriers. The question naturally arises whether such systems can approach or achieve parity with human translations. This the code  focuses, compare which model is the best for translation for low resource languages. The dataset consists of the following languages English, Afar, Amharic, Oromo, Somali, and Tigrinya. The models which were compared for the study are Long Short-Term Memory (LTSM), Convolutional Neural Network (CNN), and Transformer-based Models. the dataset is visualised to see how the words were distributed  by analysing the word length language that is in the dataset. The models were compared using the model accuracy , Precision, recall and F1-Score.  


Objective


The primary objective of this experiment is to evaluate and compare the performance of three machine translation models—Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN), and Transformer-based models—on low-resource languages. The goal is to determine which model performs best in terms of accuracy, precision, recall, and F1-score.


Dataset: 

Languages Included: English, Afar, Amharic, Oromo, Somali, and Tigrinya.

Dataset Link: https://github.com/asmelashteka/HornMT



Running the Code: 

Prerequisites

-Python (3.7 or higher)

-PyTorch : pip install torch torchvision torchaudio

-Transformers Library (for tokenization and Transformer models): pip install transformers

-Scikit-learn  : pip install scikit-learn

-SacreBLEU : pip install sacrebleu

-Matplotlib and Seaborn  : pip install matplotlib seaborn





